{
  "hash": "c64c029a483b33ea354f6dd00ee3488d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Anonymisation\"\nlightbox:\n  match: auto\n  effect: fade\n  desc-position: bottom\n  loop: false\n---\n\n\n\n\n\n\n\nexecute:\n  enabled: false\n\n---\n\nThe following code snippet is shows how I anonymise data in a DataFrame using the `Faker` library. The code generates fake names, emails, and IDs for staff or student data based on the unique IDs in the DataFrame. The anonymised data is then merged back with the original DataFrame, and the original columns are removed.\n\n\n![Pre-anonymisation Extract](./images/anon_pre.png){.gallery-image-large group=\"anon\" description=\"\"}\n\n![Post-anonymisation Extract](./images/anon_post.png){.gallery-image-large group=\"anon\" description=\"\"}\n\n<br>\n<br>\n\n::: {#b933687e .cell execution_count=1}\n``` {.python .cell-code}\nimport random\nimport hashlib\nfrom faker import Faker\nimport pandas as pd\n\n\ndef anonymise_data(df):\n    \"\"\"\n    anonymises cols in df by generating fake names, emails, and IDs.\n    \"\"\"\n    process_logger.info(\"Starting anonymisation\")\n    process_logger.info(f\"Columns in dataframe: {df.columns.tolist()}\")\n    \n    # staff or student data\n    if 'staffSplusID' in df.columns:\n        process_logger.info(\"Processing staff data\")\n        id_col = 'staffID'\n        prefix = 'staff'\n        columns_to_remove = ['staffFullName', 'staffLastName', 'staffForenames', 'staffID']\n    elif 'stuSplusID' in df.columns:\n        process_logger.info(\"Processing student data\")\n        id_col = 'studentID'\n        prefix = 'stu'\n        columns_to_remove = ['stuFullName', 'stuLastName', 'stuForenames', 'studentID']\n    else:\n        process_logger.error(\"Neither 'staffSplusID' nor 'stuSplusID' found in columns.\")\n        return df  # Return original dataframe if required columns are missing\n\n    # dictionary to store anonymised data\n    anon_data = {}\n    \n    # generate anonymised data for each unique ID\n    for unique_id in df[id_col].unique():\n        # create a seed based on the unique_id\n        seed = int(hashlib.md5(str(unique_id).encode()).hexdigest(), 16) & 0xFFFFFFFF\n        fake = Faker()\n        fake.seed_instance(seed)\n        random.seed(seed)\n\n        first_name = fake.first_name()\n        last_name = fake.last_name()\n        full_name = f\"{first_name} {last_name}\"\n        email = f\"{first_name.lower()}.{last_name.lower()}@fakemail.ac.uk\"\n        anon_id = f\"{prefix}-{random.randint(10000000, 99999999):08d}\"\n        \n        anon_data[unique_id] = {\n            f'{prefix}FirstName_anon': first_name,\n            f'{prefix}LastName_anon': last_name,\n            f'{prefix}FullName_anon': full_name,\n            f'{prefix}Email_anon': email,\n            f'{prefix}ID_anon': anon_id\n        }\n    \n    # create a new df with anonymised data\n    df_anon = pd.DataFrame.from_dict(anon_data, orient='index')\n    \n    # reset the index and rename it to match the original ID column\n    df_anon = df_anon.reset_index().rename(columns={'index': id_col})\n    \n    try:\n        # Merge anonymised data with the original DataFrame\n        df_result = pd.merge(df, df_anon, on=id_col)\n        \n        # Rmove columns that should be anonymised\n        columns_to_remove = [col for col in columns_to_remove if col in df_result.columns]\n        df_result = df_result.drop(columns=columns_to_remove)\n        \n        process_logger.info(\"Anonymisation completed successfully\")\n        return df_result\n\n    except Exception as e:\n        process_logger.error(f\"Error during anonymisation: {str(e)}\")\n        return df  # return original df if error \n```\n:::\n\n\n",
    "supporting": [
      "appendix-anonymise_files\\figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}