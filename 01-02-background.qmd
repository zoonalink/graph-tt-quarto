---
title: Background and Motivation
---

::: {callout-warning}
## TODO

-   review - reduce?
:::

Many years ago I slipped into the world of timetabling and scheduling.  I grappled with the complexities of timetable generation and optimisation and battled with trying to balance competing, but conflicting demands, like maximising room utilisation **AND** adhering to staff working patterns **ADD** producing a 'decent' timetable for the students.  Following this, I spent some years as a timetabling data manager, where my view needed to be slightly broader, encompassing the whole dataset.  These experiences exposed me not only to the intricacies of the data, systems and processes but also the intense pressures faced by timetabling teams.  The constant scrutiny, stakeholder demands and impossibility of achieving universal satisfaction left an indelible mark, highlighting the need for robust tools and metrics to understand and assess timetable quality - a factor often overshadowed by the pursuit of mere feasibility.

## Research Gap: Bridging Theory and Practice

Much of current research into university timetabling centres on combinatorial optimisation (Chen et al., 2021), that is using various sophisticated techniques designed to efficiently generate feasible solutions given a set of constraints.  The computationally-driven optimisation research is often referred to as the university course timetabing problem (UCTTP) and is categorised as NP-hard[^1], meaning finding the absolute "best" timetable is exceptionally challenging (Babaei, Karimpour and Hadidi, 2015; Herres and Schmitz, 2021; Wikipedia contributors, 2024). Consequently, significant effort has been dedicated to developing algorithms like constraint programming (Holm et al., 2022) and local search techniques such as Tabu Search and simulated annealing (Oude Vrielink et al., 2019), aiming to create workable timetables within reasonable timeframes.

However, this emphasis on computational optimisation makes use of standardised datasets and predefined constraints. While crucial for advancing algorithmic development, these idealised scenarios do not fully capture the dynamic complexity of real-world university timetabling. Universities grapple with constantly shifting demands: fluctuating student populations, evolving college preferences, resource limitations, and the ever-present need to balance diverse stakeholder needs. These complexities extend beyond simply finding a feasible solution – they necessitate tools to understand the trade-offs inherent in any timetable, enabling informed decisions about which "good" outcomes to prioritise (Lindahl, 2017). 

This is where I believe graph data structures offer unique potential. Timetables are inherently about relationships: curriculum linked to lecturers, students connected through shared modules, rooms associated with specific times and capacities. Graph databases excel in this domain, offering a way to unlock insights hidden within the complex web of a university timetable.

While algorithms excel at generating solutions, there remains a gap in post-generation analysis – e.g. the ability to delve into a timetable's nuanced impacts on student and staff experience. Despite the acknowledged importance of factors like room allocation and teaching period distribution, traditional optimisation-focused approaches lack the tools to explore these relationships in depth (Ceschia, Di Gaspero and Schaerf, 2023; Lindahl, 2017; Rudová, Müller and Murray, 2011). 

This potential for deeper analysis, coupled with the limitations of optimisation-centric approaches, motivates this exploration of graph data structures for enhancing timetable understanding and, ultimately, improving timetable quality for all stakeholders.


[^1]: "In [computational complexity theory](https://en.wikipedia.org/wiki/Computational_complexity_theory "Computational complexity theory"), a computational problem *H* is called **NP-hard** if, for every problem *L* which can be solved in [non-deterministic polynomial-time](https://en.wikipedia.org/wiki/NP_(complexity) "NP (complexity)"), there is a [polynomial-time reduction](https://en.wikipedia.org/wiki/Polynomial_time_reduction "Polynomial time reduction") from *L* to *H*." (Wikipedia contributors, 2024)

